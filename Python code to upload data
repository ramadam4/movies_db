{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58ac5453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to the database successful! ✅\n",
      "DataFrame for 'ExpertReviewsClean43LIWC.xlsx' created successfully. ✅\n",
      "'ExpertReviewsClean43LIWC.xlsx' successfully imported to table 'expert_reviews'. ✅\n",
      "DataFrame for 'metaClean43Brightspace.xlsx' created successfully. ✅\n",
      "'metaClean43Brightspace.xlsx' successfully imported to table 'meta'. ✅\n",
      "DataFrame for 'sales.xlsx' created successfully. ✅\n",
      "'sales.xlsx' successfully imported to table 'sales'. ✅\n",
      "DataFrame for 'UserReviewsClean43LIWC.xlsx' created successfully. ✅\n",
      "'UserReviewsClean43LIWC.xlsx' successfully imported to table 'user_reviews'. ✅\n",
      "Database connection closed. ✅\n"
     ]
    }
   ],
   "source": [
    "# The pandas library is often used for data manipulation and analysis in Python.\n",
    "# It provides a powerful DataFrame object for handling structured data.\n",
    "import pandas as pd\n",
    "# The sqlalchemy library is a popular Python SQL toolkit and Object-Relational Mapper (ORM).\n",
    "# It simplifies database interactions and provides a consistent interface for various database systems.\n",
    "import sqlalchemy\n",
    "# The psycopg2 library is a PostgreSQL database adapter for Python.\n",
    "# It is used by sqlalchemy to connect to PostgreSQL databases.\n",
    "import psycopg2\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define database connection details\n",
    "# --------------------------------------------------------------------------------\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create a connection engine to the PostgreSQL database using SQLAlchemy.\n",
    "# --------------------------------------------------------------------------------\n",
    "try:\n",
    "    engine = sqlalchemy.create_engine(\n",
    "        f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB_NAME}\"\n",
    "    )\n",
    "    # Test the connection to ensure it's successful.\n",
    "    connection = engine.connect()\n",
    "    print(\"Connection to the database successful! ✅\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Print an error message if the connection fails.\n",
    "    print(f\"Error connecting to the database: {e} ❌\")\n",
    "    engine = None\n",
    "    connection = None\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define file paths and corresponding table names for the Excel files.\n",
    "# --------------------------------------------------------------------------------\n",
    "files_and_tables = {\n",
    "    'ExpertReviewsClean43LIWC.xlsx': 'expert_reviews',\n",
    "    'metaClean43Brightspace.xlsx': 'meta',\n",
    "    'sales.xlsx': 'sales',\n",
    "    'UserReviewsClean43LIWC.xlsx': 'user_reviews'\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Function to import an Excel file into a PostgreSQL table.\n",
    "# --------------------------------------------------------------------------------\n",
    "def import_excel_to_postgres(file_path, table_name, engine):\n",
    "    \"\"\"\n",
    "    Reads an Excel file into a pandas DataFrame and then uploads it to a \n",
    "    PostgreSQL database table.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): The path to the Excel file.\n",
    "    - table_name (str): The name of the table to create in the database.\n",
    "    - engine (sqlalchemy.engine.base.Engine): The SQLAlchemy database engine.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file into a pandas DataFrame.\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"DataFrame for '{file_path}' created successfully. ✅\")\n",
    "        \n",
    "        # Write the DataFrame to the PostgreSQL table.\n",
    "        # if_exists='replace' will drop the table and re-create it.\n",
    "        # index=False prevents writing the DataFrame index as a column in the table.\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        print(f\"'{file_path}' successfully imported to table '{table_name}'. ✅\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Print an error message if the import fails.\n",
    "        print(f\"Error importing '{file_path}' to '{table_name}': {e} ❌\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Loop through the defined files and tables and import each one.\n",
    "# --------------------------------------------------------------------------------\n",
    "if engine is not None:\n",
    "    for file_name, table_name in files_and_tables.items():\n",
    "        # You may need to specify the full path to your Excel files if they are not \n",
    "        # in the same directory as your Python script.\n",
    "        import_excel_to_postgres(file_name, table_name, engine)\n",
    "\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Close the database connection.\n",
    "    # --------------------------------------------------------------------------------\n",
    "    connection.close()\n",
    "    print(\"Database connection closed. ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection to the database successful!\n",
      "✅ All staging tables extracted into DataFrames.\n",
      "\n",
      "--- Starting Data Transformation ---\n",
      "✅ 'sales_df' transformed.\n",
      "✅ 'meta_df' transformed.\n",
      "✅ Review DataFrames transformed.\n",
      "✅ 'genre' and 'director' lookup tables created.\n",
      "✅ Consolidated 'movies' DataFrame created.\n",
      "\n",
      "--- Starting Data Loading ---\n",
      "✅ 'movies', 'genre', and 'director' tables loaded.\n",
      "✅ Foreign key 'movie_id' added and 'sales' table updated.\n",
      "✅ Foreign key 'movie_id' added and 'meta' table updated.\n",
      "✅ Foreign key 'movie_id' added and 'expert_reviews' table updated.\n",
      "✅ Foreign key 'movie_id' added and 'user_reviews' table updated.\n",
      "\n",
      "✅ All data loaded successfully!\n",
      "✅ Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import re\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define database connection details\n",
    "# --------------------------------------------------------------------------------\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"00000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Helper Functions\n",
    "# --------------------------------------------------------------------------------\n",
    "def clean_movie_title(title):\n",
    "    \"\"\"Cleans a movie title by removing special characters and converting to lowercase.\"\"\"\n",
    "    if isinstance(title, str):\n",
    "        title = re.sub(r'[^a-zA-Z0-9\\s]', '', title)\n",
    "        return title.strip().lower()\n",
    "    return None\n",
    "\n",
    "def extract_title_from_url(url):\n",
    "    \"\"\"Extracts and cleans a movie title from a URL.\"\"\"\n",
    "    if isinstance(url, str):\n",
    "        match = re.search(r'\\/([^\\/]+?)(?:\\.\\w+)?$', url)\n",
    "        if match:\n",
    "            return clean_movie_title(match.group(1).replace('-', ' '))\n",
    "    return None\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 1. EXTRACT: Read data from PostgreSQL database We are using ETL \"Transform outside target DB; load only curated data.\" we did this for speed and data integrity\"\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "try:\n",
    "    engine = sqlalchemy.create_engine(\n",
    "        f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB_NAME}\"\n",
    "    )\n",
    "    connection = engine.connect()\n",
    "    print(\"✅ Connection to the database successful!\")\n",
    "    \n",
    "    expert_reviews_df = pd.read_sql_table('expert_reviews', engine)\n",
    "    meta_df = pd.read_sql_table('meta', engine)\n",
    "    sales_df = pd.read_sql_table('sales', engine)\n",
    "    user_reviews_df = pd.read_sql_table('user_reviews', engine)\n",
    "    print(\"✅ All staging tables extracted into DataFrames.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during extraction: {e}\")\n",
    "    if 'connection' in locals() and connection:\n",
    "        connection.close()\n",
    "    exit()\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 2. TRANSFORM: Clean and reshape data\n",
    "# --------------------------------------------------------------------------------\n",
    "print(\"\\n--- Starting Data Transformation ---\")\n",
    "\n",
    "# Drop columns that are completely empty across all DataFrames\n",
    "for df in [expert_reviews_df, meta_df, sales_df, user_reviews_df]:\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Transform 'sales_df'\n",
    "if 'title' in sales_df.columns:\n",
    "    sales_df['title_clean'] = sales_df['title'].apply(clean_movie_title)\n",
    "if 'genre' in sales_df.columns:\n",
    "    sales_df['genre'] = sales_df['genre'].astype(str).str.strip()\n",
    "if 'year' in sales_df.columns:\n",
    "    sales_df['year'] = pd.to_numeric(sales_df['year'], errors='coerce').fillna(0).astype('Int64')\n",
    "    \n",
    "# Clean and cast numerical columns in 'sales_df', ignoring dropped columns\n",
    "numerical_cols_sales = [\n",
    "    'international_box_office', 'domestic_box_office', 'worldwide_box_office', \n",
    "    'production_budget', 'opening_weekend', 'avg_run_per_theatre'\n",
    "]\n",
    "for col in numerical_cols_sales:\n",
    "    if col in sales_df.columns:\n",
    "        sales_df[col] = sales_df[col].astype(str).str.replace(r'[^0-9.]', '', regex=True)\n",
    "        sales_df[col] = pd.to_numeric(sales_df[col], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "print(\"✅ 'sales_df' transformed.\")\n",
    "\n",
    "# Transform 'meta_df'\n",
    "if 'title' in meta_df.columns:\n",
    "    meta_df['title_clean'] = meta_df['title'].apply(clean_movie_title)\n",
    "if 'studio' in meta_df.columns:\n",
    "    meta_df['studio'] = meta_df['studio'].astype(str).str.strip()\n",
    "if 'rating' in meta_df.columns:\n",
    "    meta_df['rating'] = meta_df['rating'].astype(str).str.replace(r'[^a-zA-Z0-9]', '', regex=True).str.strip()\n",
    "if 'director' in meta_df.columns:\n",
    "    meta_df['director'] = meta_df['director'].astype(str).str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True).str.strip()\n",
    "if 'RelDate' in meta_df.columns:\n",
    "    meta_df['year'] = pd.to_datetime(meta_df['RelDate'], errors='coerce').dt.year\n",
    "    meta_df['year'] = meta_df['year'].fillna(0).astype('Int64')\n",
    "if 'metascore' in meta_df.columns:\n",
    "    meta_df['metascore'] = pd.to_numeric(meta_df['metascore'], errors='coerce').fillna(0).astype('Int64')\n",
    "if 'userscore' in meta_df.columns:\n",
    "    meta_df['userscore'] = meta_df['userscore'].astype(str).str.replace('.', '', regex=False)\n",
    "    meta_df['userscore'] = pd.to_numeric(meta_df['userscore'], errors='coerce').fillna(0).astype('Int64')\n",
    "\n",
    "print(\"✅ 'meta_df' transformed.\")\n",
    "\n",
    "# Transform 'user_reviews_df' and 'expert_reviews_df'\n",
    "for df in [user_reviews_df, expert_reviews_df]:\n",
    "    if 'url' in df.columns:\n",
    "        df['title_clean'] = df['url'].apply(extract_title_from_url)\n",
    "    if 'idvscore' in df.columns:\n",
    "        df['idvscore'] = pd.to_numeric(df['idvscore'], errors='coerce')\n",
    "        df.dropna(subset=['idvscore'], inplace=True)\n",
    "        df['idvscore'] = df['idvscore'].astype('Int16')\n",
    "    if 'reviewer' in df.columns:\n",
    "        df.dropna(subset=['reviewer'], inplace=True)\n",
    "\n",
    "# Specific transformation for 'expert_reviews_df'\n",
    "if 'idvscore' in expert_reviews_df.columns:\n",
    "    expert_reviews_df['idvscore'] = expert_reviews_df['idvscore'] * 10\n",
    "\n",
    "print(\"✅ Review DataFrames transformed.\")\n",
    "\n",
    "# Create 'genre' and 'director' tables from unique values\n",
    "genre_df = pd.DataFrame(sales_df['genre'].unique(), columns=['genre_name']).dropna()\n",
    "genre_df.index.name = 'genre_id'\n",
    "genre_df.reset_index(inplace=True)\n",
    "genre_df['genre_id'] = genre_df.index + 1\n",
    "\n",
    "director_df = pd.DataFrame(meta_df['director'].unique(), columns=['director_name']).dropna()\n",
    "director_df.index.name = 'director_id'\n",
    "director_df.reset_index(inplace=True)\n",
    "director_df['director_id'] = director_df.index + 1\n",
    "\n",
    "print(\"✅ 'genre' and 'director' lookup tables created.\")\n",
    "\n",
    "# Create the consolidated 'movies' DataFrame\n",
    "consolidated_titles = pd.concat([\n",
    "    sales_df[['title_clean', 'year']].rename(columns={'title_clean': 'title'}),\n",
    "    meta_df[['title_clean', 'year']].rename(columns={'title_clean': 'title'})\n",
    "]).drop_duplicates(subset=['title', 'year'])\n",
    "\n",
    "# Fix: Select only the required columns to avoid conflicts during merge\n",
    "meta_to_merge = meta_df[['title_clean', 'year', 'rating', 'metascore', 'studio', 'runtime']].rename(columns={'title_clean': 'title'})\n",
    "sales_to_merge = sales_df[['title_clean', 'year', 'genre']].rename(columns={'title_clean': 'title'})\n",
    "\n",
    "movies_df = pd.merge(consolidated_titles, meta_to_merge, on=['title', 'year'], how='left')\n",
    "movies_df = pd.merge(movies_df, sales_to_merge, on=['title', 'year'], how='left')\n",
    "movies_df.drop_duplicates(subset=['title', 'year'], inplace=True)\n",
    "\n",
    "print(\"✅ Consolidated 'movies' DataFrame created.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 3. LOAD: Write transformed data back to PostgreSQL\n",
    "# --------------------------------------------------------------------------------\n",
    "print(\"\\n--- Starting Data Loading ---\")\n",
    "\n",
    "try:\n",
    "    # Load 'genre' and 'director' lookup tables\n",
    "    genre_df.to_sql('genre', engine, if_exists='replace', index=False)\n",
    "    director_df.to_sql('director', engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create the 'movies' table with a serial primary key\n",
    "    movies_df.to_sql('movies_temp', engine, if_exists='replace', index=False)\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(sqlalchemy.text(\"\"\"\n",
    "            CREATE TABLE movies (\n",
    "                movie_id SERIAL PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                year INTEGER,\n",
    "                rating TEXT,\n",
    "                metascore INTEGER,\n",
    "                studio TEXT,\n",
    "                runtime INTEGER,\n",
    "                genre TEXT\n",
    "            );\n",
    "            INSERT INTO movies (title, year, rating, metascore, studio, runtime, genre)\n",
    "            SELECT title, year, rating, metascore, studio, runtime, genre FROM movies_temp;\n",
    "            DROP TABLE movies_temp;\n",
    "        \"\"\"))\n",
    "    print(\"✅ 'movies', 'genre', and 'director' tables loaded.\")\n",
    "\n",
    "    # Read the new 'movies' table to get the auto-generated 'movie_id'\n",
    "    movies_df_with_id = pd.read_sql_table('movies', engine)\n",
    "\n",
    "    # Add 'movie_id' as a foreign key to staging tables\n",
    "    for df, table_name in [(sales_df, 'sales'), (meta_df, 'meta'), (expert_reviews_df, 'expert_reviews'), (user_reviews_df, 'user_reviews')]:\n",
    "        if 'title_clean' in df.columns:\n",
    "            # Create a copy to avoid SettingWithCopyWarning\n",
    "            df_copy = df.copy()\n",
    "            \n",
    "            # Use 'title_clean' and 'year' for a more accurate merge\n",
    "            merge_cols = ['title_clean']\n",
    "            if 'year' in df_copy.columns and 'year' in movies_df_with_id.columns:\n",
    "                df_merged = pd.merge(df_copy, movies_df_with_id[['title', 'year', 'movie_id']].rename(columns={'title': 'title_clean'}), \n",
    "                                     on=['title_clean', 'year'], how='left', suffixes=('', '_movies'))\n",
    "            else:\n",
    "                df_merged = pd.merge(df_copy, movies_df_with_id[['title', 'movie_id']].rename(columns={'title': 'title_clean'}),\n",
    "                                     on='title_clean', how='left')\n",
    "\n",
    "            # Drop duplicate merge columns\n",
    "            for col in ['title_movies', 'year_movies']:\n",
    "                if col in df_merged.columns:\n",
    "                    df_merged.drop(columns=[col], inplace=True)\n",
    "\n",
    "            # Load the updated DataFrame back to its table\n",
    "            df_merged.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "            print(f\"✅ Foreign key 'movie_id' added and '{table_name}' table updated.\")\n",
    "\n",
    "    print(\"\\n✅ All data loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during loading: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'connection' in locals() and connection:\n",
    "        connection.close()\n",
    "    print(\"✅ Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22f003d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Extraction Phase ---\n",
      "✅ Connection to the database successful!\n",
      "✅ All necessary tables extracted into DataFrames.\n",
      "\n",
      "--- Starting Transformation Phase ---\n",
      "\n",
      "Step 1: Creating 'reviews' DataFrame...\n",
      "✅ 'reviews' DataFrame created.\n",
      "\n",
      "Step 2: Creating 'reviewer' DataFrame...\n",
      "✅ 'reviewer' DataFrame created.\n",
      "\n",
      "Step 3: Creating 'awards' DataFrame...\n",
      "✅ 'awards' DataFrame created.\n",
      "\n",
      "Step 4: Creating 'movie_awards' DataFrame...\n",
      "✅ 'movie_awards' DataFrame created.\n",
      "\n",
      "Step 5: Creating 'movie_director' DataFrame...\n",
      "✅ 'movie_director' DataFrame created.\n",
      "\n",
      "Step 6: Creating 'director_awards' DataFrame...\n",
      "✅ 'director_awards' DataFrame created.\n",
      "\n",
      "--- Starting Loading Phase ---\n",
      "✅ Initiated database transaction.\n",
      "✅ 'reviews' table loaded.\n",
      "✅ 'reviewer' table loaded.\n",
      "✅ 'awards' table loaded.\n",
      "✅ 'movie_awards' table loaded.\n",
      "✅ 'movie_director' table loaded.\n",
      "✅ 'director_awards' table loaded.\n",
      "\n",
      "✅ All data loaded successfully!\n",
      "✅ Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "import re\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define database connection details\n",
    "# --------------------------------------------------------------------------------\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"00000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Helper Functions for Data Cleaning\n",
    "# --------------------------------------------------------------------------------\n",
    "def clean_award_name(awards_text):\n",
    "    \"\"\"Cleans award text by removing numbers and '#' symbol.\"\"\"\n",
    "    if isinstance(awards_text, str):\n",
    "        cleaned_text = re.sub(r'[0-9#]', '', awards_text).strip()\n",
    "        return [award.strip() for award in cleaned_text.split(',') if award.strip()]\n",
    "    return []\n",
    "\n",
    "def extract_ranking_from_awards(awards_text):\n",
    "    \"\"\"Extracts ranking number from the awards text.\"\"\"\n",
    "    if isinstance(awards_text, str):\n",
    "        match = re.search(r'#(\\d+)', awards_text)\n",
    "        return int(match.group(1)) if match else None\n",
    "    return None\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 1. EXTRACT: Read Data from PostgreSQL Database\n",
    "# --------------------------------------------------------------------------------\n",
    "print(\"\\n--- Starting Extraction Phase ---\")\n",
    "try:\n",
    "    engine = sqlalchemy.create_engine(\n",
    "        f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB_NAME}\"\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        print(\"✅ Connection to the database successful!\")\n",
    "        \n",
    "        expert_reviews_df = pd.read_sql_table('expert_reviews', conn)\n",
    "        user_reviews_df = pd.read_sql_table('user_reviews', conn)\n",
    "        meta_df = pd.read_sql_table('meta', conn)\n",
    "        director_df = pd.read_sql_table('director', conn)\n",
    "        movies_df = pd.read_sql_table('movies', conn)\n",
    "\n",
    "        print(\"✅ All necessary tables extracted into DataFrames.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during extraction: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 2. TRANSFORM: Clean and Reshape Data\n",
    "# --------------------------------------------------------------------------------\n",
    "print(\"\\n--- Starting Transformation Phase ---\")\n",
    "\n",
    "# Step 1: Create 'reviews' table DataFrame\n",
    "print(\"\\nStep 1: Creating 'reviews' DataFrame...\")\n",
    "review_cols = ['movie_id', 'reviewer', 'posemo', 'negemo', 'WC', 'WPS', 'idvscore']\n",
    "\n",
    "user_reviews_clean = user_reviews_df.assign(review_type='user')\n",
    "expert_reviews_clean = expert_reviews_df.assign(review_type='expert')\n",
    "\n",
    "reviews_df = pd.concat([\n",
    "    user_reviews_clean[[col for col in review_cols + ['review_type'] if col in user_reviews_clean.columns]],\n",
    "    expert_reviews_clean[[col for col in review_cols + ['review_type'] if col in expert_reviews_clean.columns]]\n",
    "], ignore_index=True)\n",
    "print(\"✅ 'reviews' DataFrame created.\")\n",
    "\n",
    "# Step 2: Create 'reviewer' table DataFrame\n",
    "print(\"\\nStep 2: Creating 'reviewer' DataFrame...\")\n",
    "reviewer_df = pd.DataFrame(reviews_df['reviewer'].dropna().unique(), columns=['reviewer_name'])\n",
    "reviewer_df.index.name = 'reviewer_id'\n",
    "reviewer_df.reset_index(inplace=True)\n",
    "reviewer_df['reviewer_id'] = reviewer_df.index + 1\n",
    "print(\"✅ 'reviewer' DataFrame created.\")\n",
    "\n",
    "# Step 3: Create 'awards' table DataFrame\n",
    "print(\"\\nStep 3: Creating 'awards' DataFrame...\")\n",
    "awards_data = meta_df['awards'].fillna('').apply(clean_award_name)\n",
    "unique_awards = awards_data.explode().dropna().unique()\n",
    "awards_df = pd.DataFrame(unique_awards, columns=['award_name'])\n",
    "awards_df.index.name = 'award_id'\n",
    "awards_df.reset_index(inplace=True)\n",
    "awards_df['award_id'] = awards_df.index + 1\n",
    "print(\"✅ 'awards' DataFrame created.\")\n",
    "\n",
    "# Step 4: Create 'movie_awards' table DataFrame\n",
    "print(\"\\nStep 4: Creating 'movie_awards' DataFrame...\")\n",
    "movie_awards_expanded = meta_df.assign(award_name=meta_df['awards'].apply(clean_award_name)).explode('award_name')\n",
    "movie_awards_expanded['ranking'] = movie_awards_expanded['awards'].apply(extract_ranking_from_awards)\n",
    "movie_awards_df = pd.merge(movie_awards_expanded, awards_df, on='award_name', how='left')\n",
    "movie_awards_df = movie_awards_df[['movie_id', 'award_id', 'award_name', 'ranking', 'year']].drop_duplicates()\n",
    "print(\"✅ 'movie_awards' DataFrame created.\")\n",
    "\n",
    "# Step 5: Create 'movie_director' table DataFrame\n",
    "print(\"\\nStep 5: Creating 'movie_director' DataFrame...\")\n",
    "movie_director_df = pd.merge(\n",
    "    meta_df[['movie_id', 'director']].dropna(),\n",
    "    director_df.rename(columns={'director_name': 'director'}),\n",
    "    on='director',\n",
    "    how='left'\n",
    ").drop_duplicates()\n",
    "movie_director_df = movie_director_df[['movie_id', 'director', 'director_id']]\n",
    "movie_director_df.rename(columns={'director': 'director_name'}, inplace=True)\n",
    "print(\"✅ 'movie_director' DataFrame created.\")\n",
    "\n",
    "# Step 6: Create 'director_awards' table DataFrame\n",
    "print(\"\\nStep 6: Creating 'director_awards' DataFrame...\")\n",
    "director_awards_df = pd.merge(\n",
    "    movie_director_df[['movie_id', 'director_id']],\n",
    "    movie_awards_df[['movie_id', 'award_id']],\n",
    "    on='movie_id',\n",
    "    how='inner'\n",
    ").drop_duplicates()\n",
    "director_awards_df = director_awards_df[['director_id', 'award_id']]\n",
    "print(\"✅ 'director_awards' DataFrame created.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 3. LOAD: Write Transformed Data to PostgreSQL\n",
    "# --------------------------------------------------------------------------------\n",
    "print(\"\\n--- Starting Loading Phase ---\")\n",
    "try:\n",
    "    with engine.begin() as conn:\n",
    "        print(\"✅ Initiated database transaction.\")\n",
    "\n",
    "        reviews_df.to_sql('reviews_temp', conn, if_exists='replace', index=False)\n",
    "        conn.execute(sqlalchemy.text(\"\"\"\n",
    "            CREATE TABLE reviews (\n",
    "                review_id SERIAL PRIMARY KEY,\n",
    "                movie_id INTEGER,\n",
    "                review_type TEXT,\n",
    "                reviewer TEXT,\n",
    "                posemo TEXT,\n",
    "                negemo TEXT,\n",
    "                \"WC\" TEXT,\n",
    "                \"WPS\" TEXT,\n",
    "                idvscore INTEGER\n",
    "            );\n",
    "            INSERT INTO reviews (movie_id, review_type, reviewer, posemo, negemo, \"WC\", \"WPS\", idvscore)\n",
    "            SELECT \"movie_id\", \"review_type\", \"reviewer\", \"posemo\", \"negemo\", \"WC\", \"WPS\", \"idvscore\" FROM reviews_temp;\n",
    "            DROP TABLE reviews_temp;\n",
    "        \"\"\"))\n",
    "        print(\"✅ 'reviews' table loaded.\")\n",
    "\n",
    "        reviewer_df.to_sql('reviewer_temp', conn, if_exists='replace', index=False)\n",
    "        conn.execute(sqlalchemy.text(\"\"\"\n",
    "            CREATE TABLE reviewer (\n",
    "                reviewer_id SERIAL PRIMARY KEY,\n",
    "                reviewer_name TEXT\n",
    "            );\n",
    "            INSERT INTO reviewer (reviewer_id, reviewer_name)\n",
    "            SELECT reviewer_id, reviewer_name FROM reviewer_temp;\n",
    "            DROP TABLE reviewer_temp;\n",
    "        \"\"\"))\n",
    "        print(\"✅ 'reviewer' table loaded.\")\n",
    "\n",
    "        awards_df.to_sql('awards_temp', conn, if_exists='replace', index=False)\n",
    "        conn.execute(sqlalchemy.text(\"\"\"\n",
    "            CREATE TABLE awards (\n",
    "                award_id SERIAL PRIMARY KEY,\n",
    "                award_name TEXT\n",
    "            );\n",
    "            INSERT INTO awards (award_name)\n",
    "            SELECT award_name FROM awards_temp;\n",
    "            DROP TABLE awards_temp;\n",
    "        \"\"\"))\n",
    "        print(\"✅ 'awards' table loaded.\")\n",
    "\n",
    "        movie_awards_df.to_sql('movie_awards', conn, if_exists='replace', index=False)\n",
    "        print(\"✅ 'movie_awards' table loaded.\")\n",
    "\n",
    "        movie_director_df.to_sql('movie_director', conn, if_exists='replace', index=False)\n",
    "        print(\"✅ 'movie_director' table loaded.\")\n",
    "\n",
    "        director_awards_df.to_sql('director_awards', conn, if_exists='replace', index=False)\n",
    "        print(\"✅ 'director_awards' table loaded.\")\n",
    "            \n",
    "    print(\"\\n✅ All data loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during loading: {e}\")\n",
    "    print(\"Database transaction failed. Rolling back changes to ensure original data is not impacted.\")\n",
    "\n",
    "finally:\n",
    "    if 'conn' in locals():\n",
    "        conn.close()\n",
    "    print(\"✅ Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "56f42988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing table: 'user_reviews'\n",
      "Successfully updated 40222 rows in table 'user_reviews'.\n",
      "Changes for table 'user_reviews' have been committed.\n",
      "\n",
      "Processing table: 'expert_reviews'\n",
      "Successfully updated 18306 rows in table 'expert_reviews'.\n",
      "Changes for table 'expert_reviews' have been committed.\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "########### We want to apply a fix now for the title_clean in reviews tables###############\n",
    "# Database connection details. Please ensure these are correct for your environment.\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"0000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "def clean_title_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and cleans a movie title from a URL path.\n",
    "    For example, 'https://example.com/movie-title-here' becomes 'movie title here'.\n",
    "    The function returns the title in lowercase.\n",
    "    \"\"\"\n",
    "    # Parse the URL to get the path\n",
    "    parsed_url = urlparse(url)\n",
    "    path = parsed_url.path.strip('/')\n",
    "    \n",
    "    # Split the path by \"/\" and get the last part which is likely the movie title slug\n",
    "    title_slug = path.split('/')[-1]\n",
    "    \n",
    "    # Remove any four-digit years at the end of the slug\n",
    "    title_slug = re.sub(r'-\\d{4}$', '', title_slug)\n",
    "    \n",
    "    # Replace hyphens and underscores with spaces\n",
    "    clean_title = title_slug.replace('-', ' ').replace('_', ' ')\n",
    "    \n",
    "    # Return the title in lowercase\n",
    "    return clean_title.lower()\n",
    "\n",
    "def extract_year_from_url(url: str) -> int | None:\n",
    "    \"\"\"\n",
    "    Extracts a four-digit year from a URL path.\n",
    "    For example, 'https://example.com/movie-title-1980' returns 1980.\n",
    "    Returns None if no year is found.\n",
    "    \"\"\"\n",
    "    # Use a regular expression to find a four-digit number at the end of the URL\n",
    "    match = re.search(r'(\\d{4})/?$', url)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def update_tables():\n",
    "    \"\"\"\n",
    "    Connects to the database and updates the title_clean and year columns\n",
    "    for both 'user_reviews' and 'expert_reviews' tables.\n",
    "    This version uses a single, more efficient batch update to improve performance.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            host=HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        # List of tables to process\n",
    "        tables = [\"user_reviews\", \"expert_reviews\"]\n",
    "\n",
    "        for table_name in tables:\n",
    "            print(f\"\\nProcessing table: '{table_name}'\")\n",
    "            # Fetch all rows with 'url' where 'movie_id' is NULL\n",
    "            cur.execute(f\"SELECT url FROM {table_name} WHERE movie_id IS NULL\")\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                print(f\"No rows found in table '{table_name}' with a NULL movie_id.\")\n",
    "                continue\n",
    "\n",
    "            # Prepare a list of tuples for the batch update\n",
    "            updates = []\n",
    "            for row in rows:\n",
    "                url = row[0]\n",
    "                if url:\n",
    "                    title_clean = clean_title_from_url(url)\n",
    "                    year = extract_year_from_url(url)\n",
    "                    updates.append((title_clean, year, url))\n",
    "\n",
    "            if updates:\n",
    "                # Construct the single batch UPDATE query\n",
    "                # This is much faster than running a separate UPDATE for each row.\n",
    "                values_clause = \", \".join(cur.mogrify(\"(%s, %s, %s)\", item).decode('utf-8') for item in updates)\n",
    "                update_query = f\"\"\"\n",
    "                    UPDATE {table_name}\n",
    "                    SET\n",
    "                        title_clean = temp_table.title_clean,\n",
    "                        year = temp_table.year\n",
    "                    FROM (VALUES {values_clause}) AS temp_table(title_clean, year, url)\n",
    "                    WHERE {table_name}.url = temp_table.url AND {table_name}.movie_id IS NULL;\n",
    "                \"\"\"\n",
    "                cur.execute(update_query)\n",
    "                print(f\"Successfully updated {cur.rowcount} rows in table '{table_name}'.\")\n",
    "\n",
    "            # Commit the changes for the current table\n",
    "            conn.commit()\n",
    "            print(f\"Changes for table '{table_name}' have been committed.\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        # Rollback the transaction in case of an error\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    update_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82a3805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "\n",
      "Processing table: 'user_reviews'\n",
      "Successfully updated 14255 rows in table 'user_reviews'.\n",
      "Changes for table 'user_reviews' have been committed.\n",
      "\n",
      "Processing table: 'expert_reviews'\n",
      "Successfully updated 7873 rows in table 'expert_reviews'.\n",
      "Changes for table 'expert_reviews' have been committed.\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "#######FIX############# this code update movie id in reviews tables where it's null###############\n",
    "# Database connection details. Please ensure these are correct for your environment.\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"00000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "def clean_title_from_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and cleans a movie title from a URL path.\n",
    "    For example, 'https://example.com/movie-title-here' becomes 'movie title here'.\n",
    "    The function returns the title in lowercase.\n",
    "    \"\"\"\n",
    "    # Parse the URL to get the path\n",
    "    parsed_url = urlparse(url)\n",
    "    path = parsed_url.path.strip('/')\n",
    "    \n",
    "    # Split the path by \"/\" and get the last part which is likely the movie title slug\n",
    "    title_slug = path.split('/')[-1]\n",
    "    \n",
    "    # Remove any four-digit years at the end of the slug\n",
    "    title_slug = re.sub(r'-\\d{4}$', '', title_slug)\n",
    "    \n",
    "    # Replace hyphens and underscores with spaces\n",
    "    clean_title = title_slug.replace('-', ' ').replace('_', ' ')\n",
    "    \n",
    "    # Return the title in lowercase\n",
    "    return clean_title.lower()\n",
    "\n",
    "def extract_year_from_url(url: str) -> int | None:\n",
    "    \"\"\"\n",
    "    Extracts a four-digit year from a URL path.\n",
    "    For example, 'https://example.com/movie-title-1980' returns 1980.\n",
    "    Returns None if no year is found.\n",
    "    \"\"\"\n",
    "    # Use a regular expression to find a four-digit number at the end of the URL\n",
    "    match = re.search(r'(\\d{4})/?$', url)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def update_tables():\n",
    "    \"\"\"\n",
    "    Connects to the database and updates the title_clean, year, and movie_id columns\n",
    "    for both 'user_reviews' and 'expert_reviews' tables.\n",
    "    This version uses a single, more efficient batch update to improve performance.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            host=HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        # List of tables to process\n",
    "        tables = [\"user_reviews\", \"expert_reviews\"]\n",
    "\n",
    "        for table_name in tables:\n",
    "            print(f\"\\nProcessing table: '{table_name}'\")\n",
    "            # Fetch url, title_clean, and year for rows where 'movie_id' is NULL\n",
    "            cur.execute(f\"SELECT url, title_clean, year FROM {table_name} WHERE movie_id IS NULL\")\n",
    "            rows = cur.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                print(f\"No rows found in table '{table_name}' with a NULL movie_id.\")\n",
    "                continue\n",
    "\n",
    "            # Prepare a list of tuples for the batch update\n",
    "            updates = []\n",
    "            for url, title_clean, year in rows:\n",
    "                if not url or not title_clean or not year:\n",
    "                    continue\n",
    "                \n",
    "                # Look up the movie_id in the 'movies' table using existing title_clean and year\n",
    "                cur.execute(\n",
    "                    f\"SELECT movie_id FROM movies WHERE title = %s AND year = %s\",\n",
    "                    (title_clean, year)\n",
    "                )\n",
    "                movie_id_row = cur.fetchone()\n",
    "                movie_id = movie_id_row[0] if movie_id_row else None\n",
    "\n",
    "                if movie_id:\n",
    "                    updates.append((movie_id, url))\n",
    "\n",
    "            if updates:\n",
    "                # Construct the single batch UPDATE query for movie_id\n",
    "                values_clause = \", \".join(cur.mogrify(\"(%s, %s)\", item).decode('utf-8') for item in updates)\n",
    "                update_query = f\"\"\"\n",
    "                    UPDATE {table_name}\n",
    "                    SET\n",
    "                        movie_id = temp_table.movie_id\n",
    "                    FROM (VALUES {values_clause}) AS temp_table(movie_id, url)\n",
    "                    WHERE {table_name}.url = temp_table.url AND {table_name}.movie_id IS NULL;\n",
    "                \"\"\"\n",
    "                cur.execute(update_query)\n",
    "                print(f\"Successfully updated {cur.rowcount} rows in table '{table_name}'.\")\n",
    "\n",
    "            # Commit the changes for the current table\n",
    "            conn.commit()\n",
    "            print(f\"Changes for table '{table_name}' have been committed.\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        # Rollback the transaction in case of an error\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    update_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0bb4dda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "Existing 'reviews' table dropped.\n",
      "New 'reviews' table created successfully.\n",
      "Database error: column \"wc\" does not exist\n",
      "LINE 3: ... 'user' AS review_type, reviewer, posemo, negemo, wc, wps, i...\n",
      "                                                             ^\n",
      "DETAIL:  There is a column named \"wc\" in table \"reviews\", but it cannot be referenced from this part of the query.\n",
      "\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection details\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"0000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "def create_and_populate_reviews_table():\n",
    "    \"\"\"\n",
    "    Connects to the database, drops an existing 'reviews' table if it exists,\n",
    "    creates a new 'reviews' table, and populates it with data from 'user_reviews'\n",
    "    and 'expert_reviews'.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            host=HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        # Drop the 'reviews' table if it already exists to ensure a clean state\n",
    "        cur.execute(\"DROP TABLE IF EXISTS reviews CASCADE;\")\n",
    "        print(\"Existing 'reviews' table dropped.\")\n",
    "\n",
    "        # Create the new 'reviews' table\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE reviews (\n",
    "                review_id SERIAL PRIMARY KEY,\n",
    "                movie_id INTEGER,\n",
    "                review_type TEXT NOT NULL,\n",
    "                reviewer TEXT,\n",
    "                posemo TEXT,\n",
    "                negemo TEXT,\n",
    "                WC TEXT,\n",
    "                WPS TEXT,\n",
    "                idvscore DOUBLE PRECISION\n",
    "            );\n",
    "        \"\"\")\n",
    "        print(\"New 'reviews' table created successfully.\")\n",
    "\n",
    "        # Insert data from 'user_reviews' into the new 'reviews' table\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO reviews (movie_id, review_type, reviewer, posemo, negemo, WC, WPS, idvscore)\n",
    "            SELECT movie_id, 'user' AS review_type, reviewer, posemo, negemo, wc, wps, idvscore\n",
    "            FROM user_reviews;\n",
    "        \"\"\")\n",
    "        user_rows_inserted = cur.rowcount\n",
    "        print(f\"Successfully inserted {user_rows_inserted} rows from 'user_reviews'.\")\n",
    "\n",
    "        # Insert data from 'expert_reviews' into the new 'reviews' table\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO reviews (movie_id, review_type, reviewer, posemo, negemo, WC, WPS, idvscore)\n",
    "            SELECT movie_id, 'expert' AS review_type, reviewer, posemo, negemo, wc, wps, idvscore\n",
    "            FROM expert_reviews;\n",
    "        \"\"\")\n",
    "        expert_rows_inserted = cur.rowcount\n",
    "        print(f\"Successfully inserted {expert_rows_inserted} rows from 'expert_reviews'.\")\n",
    "\n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "        print(\"All changes have been committed to the database.\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        # Rollback the transaction in case of an error\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_and_populate_reviews_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful.\n",
      "Existing 'reviews' table dropped.\n",
      "New 'reviews' table created successfully.\n",
      "Successfully inserted 333339 rows from 'user_reviews'.\n",
      "Successfully inserted 258830 rows from 'expert_reviews'.\n",
      "All changes have been committed to the database.\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "########### This fix creates the reviews table, add the type and assign movie_id where not available #### \n",
    "#### We have updated the SQL queries beacause postgres is annoying with case sensitivity so we added \"\" ##############\n",
    "# Database connection details\n",
    "DB_NAME = \"movies_db\"\n",
    "USER = \"postgres\"\n",
    "PASSWORD = \"000000000\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "\n",
    "def create_and_populate_reviews_table():\n",
    "    \"\"\"\n",
    "    Connects to the database, drops an existing 'reviews' table if it exists,\n",
    "    creates a new 'reviews' table, and populates it with data from 'user_reviews'\n",
    "    and 'expert_reviews'.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        # Connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=DB_NAME,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            host=HOST,\n",
    "            port=PORT\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        # Drop the 'reviews' table if it already exists to ensure a clean state\n",
    "        cur.execute(\"DROP TABLE IF EXISTS reviews CASCADE;\")\n",
    "        print(\"Existing 'reviews' table dropped.\")\n",
    "\n",
    "        # Create the new 'reviews' table\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE reviews (\n",
    "                review_id SERIAL PRIMARY KEY,\n",
    "                movie_id INTEGER,\n",
    "                review_type TEXT NOT NULL,\n",
    "                reviewer TEXT,\n",
    "                posemo TEXT,\n",
    "                negemo TEXT,\n",
    "                \"WC\" TEXT,\n",
    "                \"WPS\" TEXT,\n",
    "                idvscore DOUBLE PRECISION\n",
    "            );\n",
    "        \"\"\")\n",
    "        print(\"New 'reviews' table created successfully.\")\n",
    "\n",
    "        # Insert data from 'user_reviews' into the new 'reviews' table\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO reviews (\"movie_id\", \"review_type\", \"reviewer\", \"posemo\", \"negemo\", \"WC\", \"WPS\", \"idvscore\")\n",
    "            SELECT \"movie_id\", 'user' AS \"review_type\", \"reviewer\", \"posemo\", \"negemo\", \"WC\", \"WPS\", \"idvscore\"\n",
    "            FROM user_reviews;\n",
    "        \"\"\")\n",
    "        user_rows_inserted = cur.rowcount\n",
    "        print(f\"Successfully inserted {user_rows_inserted} rows from 'user_reviews'.\")\n",
    "\n",
    "        # Insert data from 'expert_reviews' into the new 'reviews' table\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO reviews (\"movie_id\", \"review_type\", \"reviewer\", \"posemo\", \"negemo\", \"WC\", \"WPS\", \"idvscore\")\n",
    "            SELECT \"movie_id\", 'expert' AS \"review_type\", \"reviewer\", \"posemo\", \"negemo\", \"WC\", \"WPS\", \"idvscore\"\n",
    "            FROM expert_reviews;\n",
    "        \"\"\")\n",
    "        expert_rows_inserted = cur.rowcount\n",
    "        print(f\"Successfully inserted {expert_rows_inserted} rows from 'expert_reviews'.\")\n",
    "\n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "        print(\"All changes have been committed to the database.\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        # Rollback the transaction in case of an error\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_and_populate_reviews_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906bbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
